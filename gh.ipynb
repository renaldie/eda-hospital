{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821402b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "Could you please complete your question? For example, are you asking about:\n",
      "\n",
      "- Why does the sky look blue?\n",
      "- Why does ice melt at 0°C?\n",
      "- Why does gravity pull objects downward?\n",
      "- Why does a battery run out?\n",
      "- Why does my computer slow down?\n",
      "\n",
      "Tell me the topic and any specifics, and I’ll explain.\n",
      "\n",
      "Reasoning: **Clarifying the user's question**\n",
      "\n",
      "I see we have a prompt starting with \"Why does,\" which seems incomplete. It looks like the user might want some help, so I’ll ask a clarifying question. Maybe I can suggest a few topics, like, \"Why does the sky look blue?\" I’ll encourage the user to complete their question and let them know I’m here to help with explanations. Keeping my response concise should be helpful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.callbacks import UsageMetadataCallbackHandler\n",
    "from pydantic_settings import BaseSettings\n",
    "from pydantic import Field, SecretStr\n",
    "from langchain_core.callbacks import UsageMetadataCallbackHandler\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "usage_callback = UsageMetadataCallbackHandler()\n",
    "\n",
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(OPENAI_API_KEY)\n",
    "usage_callback = UsageMetadataCallbackHandler()\n",
    "\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "LLM_OPENAI = ChatOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-5-nano\",\n",
    "    output_version=\"responses/v1\",\n",
    "    reasoning={\"effort\": \"low\", \"summary\": \"auto\"},\n",
    "    callbacks=[usage_callback],\n",
    "    verbosity=\"low\",\n",
    ")\n",
    "\n",
    "reasoning_traces = []\n",
    "answer_text = []\n",
    "\n",
    "for chunk in LLM_OPENAI.stream(\"Why does\"):\n",
    "    if isinstance(chunk.content, list):\n",
    "        for item in chunk.content:\n",
    "            # Collect reasoning traces\n",
    "            if (\n",
    "                isinstance(item, dict)\n",
    "                and item.get(\"type\") == \"reasoning\"\n",
    "                and \"summary\" in item\n",
    "            ):\n",
    "                for summary_item in item[\"summary\"]:\n",
    "                    if summary_item.get(\"type\") == \"summary_text\":\n",
    "                        reasoning_traces.append(summary_item[\"text\"])\n",
    "                        print(summary_item[\"text\"], end=\"\", flush=True)\n",
    "\n",
    "            # Collect answer text\n",
    "            if isinstance(item, dict) and item.get(\"type\") == \"text\" and \"text\" in item:\n",
    "                answer_text.append(item[\"text\"])\n",
    "                print(item[\"text\"], end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\\nReasoning:\", \"\".join(reasoning_traces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e475e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    input=\"What was two positive news story from today in the US of any topic from any source\",\n",
    "    stream=True,\n",
    "    include=[\"web_search_call.action.sources\"],\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    reasoning={\"effort\": \"low\"},\n",
    ")\n",
    "\n",
    "browsed_list = []\n",
    "sources_dict = {}\n",
    "\n",
    "for event in response:\n",
    "    # print(event)\n",
    "    if event.type == \"response.output_text.delta\":\n",
    "        print(f\"Main Context is: {event.delta}\", end=\"\", flush=True)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    # Collect browsed sites\n",
    "    if event.type == \"response.output_item.done\":\n",
    "        if hasattr(event.item, \"type\") and event.item.type == \"web_search_call\":\n",
    "            if event.item.status == \"completed\" and event.item.action is not None:\n",
    "                # Extract URLs and append to sources_list\n",
    "                websites = [source.url for source in event.item.action.sources]\n",
    "                browsed_list.extend(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c0ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "LLM_OLLAMA = ChatOllama(model=\"llama3.2:1b-instruct-q4_K_M\", temperature=0)\n",
    "resp = LLM_OLLAMA.stream(\"What is the capital of France?\")\n",
    "for event in resp:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f4ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "print(os.getenv(\"OPENAI_API_KEY1\"))\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY1\"))\n",
    "\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    input=\"Give me one random news of today from any source of any kind\",\n",
    "    stream=True,\n",
    "    include=[\"web_search_call.action.sources\"],\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    reasoning={\"effort\": \"low\"},\n",
    ")\n",
    "browsed = {}\n",
    "\n",
    "for event in response:\n",
    "    # Sources\n",
    "    if event.type == \"response.output_item.done\":\n",
    "        if hasattr(event.item, \"type\") and event.item.type == \"web_search_call\":\n",
    "            if event.item.action is not None:\n",
    "                query = getattr(event.item.action, \"query\", None)\n",
    "                sources = getattr(event.item.action, \"sources\", [])\n",
    "\n",
    "                if query:  # Only proceed if query exists\n",
    "                    websites = [source.url for source in sources]\n",
    "                    browsed[query] = websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79b7bd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news today': ['https://www.ndtv.com/education/school-assembly-news-headlines-october-27-top-national-world-business-sports-news-9519881',\n",
       "  'https://www.moneycontrol.com/education/school-assembly-news-headlines-27-october-2025-national-international-business-and-sports-updates-article-13632744.html',\n",
       "  'https://en.wikipedia.org/wiki/News_Today',\n",
       "  'https://www.reuters.com/business/finance/global-markets-view-usa-2025-10-22/',\n",
       "  'https://www.ft.com/content/2a8e13ed-beda-4fe4-94fe-de963df3cff9',\n",
       "  'https://en.wikipedia.org/wiki/Today_%28Thames_Television_series%29',\n",
       "  'https://www.ft.com/content/5e5379e4-715f-4f85-80b2-ffc334a51fc6',\n",
       "  'https://en.wikipedia.org/wiki/Early_Today',\n",
       "  'https://en.wikipedia.org/wiki/Today_in_New_York',\n",
       "  'https://en.wikipedia.org/wiki/2025_in_Ethiopia',\n",
       "  'https://usnewstoday.net/'],\n",
       " 'site:reuters.com October 27, 2025 Reuters': ['https://www.indiatoday.in/amp/education-today/news/story/top-news-headlines-for-school-assembly-october-27-2808697-2025-10-27',\n",
       "  'https://www.indiatoday.in/education-today/news/story/top-news-headlines-for-school-assembly-october-27-2808697-2025-10-27',\n",
       "  'https://isitaholidaytoday.com/date/October-27-2025',\n",
       "  'https://timesofindia.indiatimes.com/astrology/horoscope/love-horoscope-today-october-27-2025-what-the-stars-say-about-your-love-life/articleshow/124829645.cms',\n",
       "  'https://timesofindia.indiatimes.com/astrology/planets-transits/mars-homecoming-in-scorpio-2025-hidden-opportunities-await-these-zodiac-signs/articleshow/124814224.cms',\n",
       "  'https://timesofindia.indiatimes.com/astrology/horoscope/horoscope-today-october-27-2025-mars-transit-in-scorpio-chhath-puja-to-bring-power-shifts-these-zodiac-signs-will-take-control-of-destiny/articleshow/124792686.cms',\n",
       "  'https://timesofindia.indiatimes.com/astrology/horoscope/horoscope-tomorrow-october-27-2025-unexpected-opportunities-ahead-fortune-favours-these-zodiac-signs/articleshow/124790843.cms']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browsed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda-hospital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
